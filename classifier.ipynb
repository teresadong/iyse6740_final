{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "#!pip install mahotas\n",
    "#-----------------------------------\n",
    "# GLOBAL FEATURE EXTRACTION\n",
    "#-----------------------------------\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "#--------------------\n",
    "# tunable-parameters\n",
    "#--------------------\n",
    "\n",
    "data_dir = 'dogs/working/resized'\n",
    "output_dir = 'dogs/output/skmodel_raw'\n",
    "train_path       = f\"{data_dir}/train\"\n",
    "test_path       = f\"{data_dir}/test\"\n",
    "h5_data_train          = f'{output_dir}/data_train.h5'\n",
    "h5_labels_train        = f'{output_dir}/labels_train.h5'\n",
    "h5_data_test          = f'{output_dir}/data_test.h5'\n",
    "h5_labels_test        = f'{output_dir}/labels_test.h5'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Get Training Data\n",
    "train_df = pd.read_csv(data_dir+'/train_labels_top20.csv')\n",
    "\n",
    "# Get Test Data\n",
    "test_df = pd.read_csv(data_dir+'/test_labels_top20.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# get the training labels\n",
    "train_labels = list(set(train_df.label_name.values))\n",
    "\n",
    "# get the training labels\n",
    "test_labels = list(set(test_df.label_name.values))\n",
    "\n",
    "# sort the training labels\n",
    "train_labels.sort()\n",
    "print(train_labels)\n",
    "test_labels.sort()\n",
    "print(test_labels)\n",
    "\n",
    "# empty lists to hold feature vectors and labels\n",
    "global_features_train = []\n",
    "labels_train          = []\n",
    "\n",
    "# empty lists to hold feature vectors and labels\n",
    "global_features_test = []\n",
    "labels_test          = []"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['n02085936-Maltese_dog', 'n02086240-Shih-Tzu', 'n02086910-papillon', 'n02088094-Afghan_hound', 'n02090721-Irish_wolfhound', 'n02091831-Saluki', 'n02092002-Scottish_deerhound', 'n02095889-Sealyham_terrier', 'n02096051-Airedale', 'n02096177-cairn', 'n02097474-Tibetan_terrier', 'n02107683-Bernese_mountain_dog', 'n02108000-EntleBucher', 'n02110806-basenji', 'n02110958-pug', 'n02111129-Leonberg', 'n02111277-Newfoundland', 'n02111500-Great_Pyrenees', 'n02111889-Samoyed', 'n02112018-Pomeranian']\n",
      "['n02085936-Maltese_dog', 'n02086240-Shih-Tzu', 'n02086910-papillon', 'n02088094-Afghan_hound', 'n02090721-Irish_wolfhound', 'n02091831-Saluki', 'n02092002-Scottish_deerhound', 'n02095889-Sealyham_terrier', 'n02096051-Airedale', 'n02096177-cairn', 'n02097474-Tibetan_terrier', 'n02107683-Bernese_mountain_dog', 'n02108000-EntleBucher', 'n02110806-basenji', 'n02110958-pug', 'n02111129-Leonberg', 'n02111277-Newfoundland', 'n02111500-Great_Pyrenees', 'n02111889-Samoyed', 'n02112018-Pomeranian']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "import os\n",
    "\n",
    "# loop over the training data sub-folders\n",
    "for training_name in train_labels:\n",
    "    # join the training data path and each species training folder\n",
    "    train_dir = os.path.join(train_path, training_name)\n",
    "    test_dir = os.path.join(test_path, training_name)\n",
    "    \n",
    "    # get the current training label\n",
    "    current_label = training_name\n",
    "\n",
    "\n",
    "    # Process training directory\n",
    "    images = os.listdir(train_dir)\n",
    "    \n",
    "    # print(len(images))\n",
    "    for img in images:\n",
    "\n",
    "        # # get the image file name\n",
    "        file = train_dir + \"/\" + img \n",
    "\n",
    "        # read the image and resize it to a fixed-size\n",
    "        image = cv2.imread(file)\n",
    "\n",
    "        ####################################\n",
    "        # Global Feature extraction\n",
    "        ####################################\n",
    "        # convert image into a 1-dimensional numpy array\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_1d = image.flatten()\n",
    "\n",
    "    \n",
    "        ###################################\n",
    "        # Concatenate global features\n",
    "        ###################################\n",
    "        \n",
    "        global_feature = image_1d\n",
    "\n",
    "        # update the list of labels and feature vectors\n",
    "        labels_train.append(current_label)\n",
    "        global_features_train.append(global_feature)\n",
    "\n",
    "    print(\"[STATUS] training processed folder: {}\".format(current_label))\n",
    "\n",
    "    # Process test directory\n",
    "    #list images in the directory\n",
    "    images = os.listdir(test_dir)\n",
    "    \n",
    "    # print(len(images))\n",
    "    for img in images:\n",
    "\n",
    "        # # get the image file name\n",
    "        file = test_dir + \"/\" + img \n",
    "\n",
    "        # read the image and resize it to a fixed-size\n",
    "        image = cv2.imread(file)\n",
    "        # image = cv2.resize(image, fixed_size)\n",
    "\n",
    "        ####################################\n",
    "        # Global Feature extraction\n",
    "        ####################################\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_1d = image.flatten()\n",
    "\n",
    "        ###################################\n",
    "        # Concatenate global features\n",
    "        ###################################\n",
    "        \n",
    "        global_feature = image_1d\n",
    "\n",
    "        # update the list of labels and feature vectors\n",
    "        labels_test.append(current_label)\n",
    "        global_features_test.append(global_feature)\n",
    "\n",
    "    print(\"[STATUS] test processed folder: {}\".format(current_label))\n",
    "\n",
    "print(\"[STATUS] completed Global Feature Extraction...\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[STATUS] training processed folder: n02085936-Maltese_dog\n",
      "[STATUS] test processed folder: n02085936-Maltese_dog\n",
      "[STATUS] training processed folder: n02086240-Shih-Tzu\n",
      "[STATUS] test processed folder: n02086240-Shih-Tzu\n",
      "[STATUS] training processed folder: n02086910-papillon\n",
      "[STATUS] test processed folder: n02086910-papillon\n",
      "[STATUS] training processed folder: n02088094-Afghan_hound\n",
      "[STATUS] test processed folder: n02088094-Afghan_hound\n",
      "[STATUS] training processed folder: n02090721-Irish_wolfhound\n",
      "[STATUS] test processed folder: n02090721-Irish_wolfhound\n",
      "[STATUS] training processed folder: n02091831-Saluki\n",
      "[STATUS] test processed folder: n02091831-Saluki\n",
      "[STATUS] training processed folder: n02092002-Scottish_deerhound\n",
      "[STATUS] test processed folder: n02092002-Scottish_deerhound\n",
      "[STATUS] training processed folder: n02095889-Sealyham_terrier\n",
      "[STATUS] test processed folder: n02095889-Sealyham_terrier\n",
      "[STATUS] training processed folder: n02096051-Airedale\n",
      "[STATUS] test processed folder: n02096051-Airedale\n",
      "[STATUS] training processed folder: n02096177-cairn\n",
      "[STATUS] test processed folder: n02096177-cairn\n",
      "[STATUS] training processed folder: n02097474-Tibetan_terrier\n",
      "[STATUS] test processed folder: n02097474-Tibetan_terrier\n",
      "[STATUS] training processed folder: n02107683-Bernese_mountain_dog\n",
      "[STATUS] test processed folder: n02107683-Bernese_mountain_dog\n",
      "[STATUS] training processed folder: n02108000-EntleBucher\n",
      "[STATUS] test processed folder: n02108000-EntleBucher\n",
      "[STATUS] training processed folder: n02110806-basenji\n",
      "[STATUS] test processed folder: n02110806-basenji\n",
      "[STATUS] training processed folder: n02110958-pug\n",
      "[STATUS] test processed folder: n02110958-pug\n",
      "[STATUS] training processed folder: n02111129-Leonberg\n",
      "[STATUS] test processed folder: n02111129-Leonberg\n",
      "[STATUS] training processed folder: n02111277-Newfoundland\n",
      "[STATUS] test processed folder: n02111277-Newfoundland\n",
      "[STATUS] training processed folder: n02111500-Great_Pyrenees\n",
      "[STATUS] test processed folder: n02111500-Great_Pyrenees\n",
      "[STATUS] training processed folder: n02111889-Samoyed\n",
      "[STATUS] test processed folder: n02111889-Samoyed\n",
      "[STATUS] training processed folder: n02112018-Pomeranian\n",
      "[STATUS] test processed folder: n02112018-Pomeranian\n",
      "[STATUS] completed Global Feature Extraction...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# get the overall feature vector size\n",
    "print(\"[STATUS] train feature vector size {}\".format(np.array(global_features_train).shape))\n",
    "print(\"[STATUS] test feature vector size {}\".format(np.array(global_features_test).shape))\n",
    "\n",
    "# get the overall training label size\n",
    "print(\"[STATUS] training Labels {}\".format(np.array(labels_train).shape))\n",
    "print(\"[STATUS] test Labels {}\".format(np.array(labels_test).shape))\n",
    "\n",
    "# encode the target labels\n",
    "targetNames = np.unique(labels_train)\n",
    "le          = LabelEncoder()\n",
    "le.fit(labels_train)\n",
    "target_train      =  le.transform(labels_train)\n",
    "target_test      = le.transform(labels_test)\n",
    "\n",
    "print(\"[STATUS] training labels encoded...\")\n",
    "print(\"[STATUS] testing labels encoded...\")\n",
    "\n",
    "# scale features in the range (0-1)\n",
    "scaler  = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaled_features_train = scaler.fit_transform(global_features_train)\n",
    "rescaled_features_test = scaler.fit_transform(global_features_test)\n",
    "print(\"[STATUS] feature vector normalized...\")\n",
    "\n",
    "print(\"[STATUS] train target labels: {}\".format(target_train))\n",
    "print(\"[STATUS] train target labels shape: {}\".format(target_train.shape))\n",
    "\n",
    "print(\"[STATUS] test target labels: {}\".format(target_test))\n",
    "print(\"[STATUS] test target labels shape: {}\".format(target_test.shape))\n",
    "\n",
    "# save the feature vector using HDF5\n",
    "h5f_data_train = h5py.File(h5_data_train, 'w')\n",
    "h5f_data_train.create_dataset('dataset_1', data=np.array(rescaled_features_train))\n",
    "\n",
    "h5f_data_test = h5py.File(h5_data_test, 'w')\n",
    "h5f_data_test.create_dataset('dataset_1', data=np.array(rescaled_features_test))\n",
    "\n",
    "\n",
    "h5f_label_train = h5py.File(h5_labels_train, 'w')\n",
    "h5f_label_train.create_dataset('dataset_1', data=np.array(target_train))\n",
    "\n",
    "h5f_label_test = h5py.File(h5_labels_test, 'w')\n",
    "h5f_label_test.create_dataset('dataset_1', data=np.array(target_test))\n",
    "\n",
    "h5f_data_train.close()\n",
    "h5f_label_train.close()\n",
    "h5f_data_test.close()\n",
    "h5f_label_test.close()\n",
    "\n",
    "\n",
    "print(\"[STATUS] end of training..\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[STATUS] train feature vector size (3417, 154587)\n",
      "[STATUS] test feature vector size (825, 154587)\n",
      "[STATUS] training Labels (3417,)\n",
      "[STATUS] test Labels (825,)\n",
      "[STATUS] training labels encoded...\n",
      "[STATUS] testing labels encoded...\n",
      "[STATUS] feature vector normalized...\n",
      "[STATUS] train target labels: [ 0  0  0 ... 19 19 19]\n",
      "[STATUS] train target labels shape: (3417,)\n",
      "[STATUS] test target labels: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9  9  9  9  9  9  9  9  9  9  9 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 13\n",
      " 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
      " 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 17\n",
      " 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      " 17 17 17 17 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18\n",
      " 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18\n",
      " 18 18 18 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19 19 19]\n",
      "[STATUS] test target labels shape: (825,)\n",
      "[STATUS] end of training..\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load in the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "#-----------------------------------\n",
    "# TRAINING OUR MODEL\n",
    "#-----------------------------------\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import warnings\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.externals import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#--------------------\n",
    "# tunable-parameters\n",
    "#--------------------\n",
    "num_trees = 100\n",
    "# test_size = 0.10\n",
    "seed      = 123\n",
    "\n",
    "scoring    = \"accuracy\"\n",
    "\n",
    "# create all the machine learning models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=seed)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, random_state=seed)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(random_state=seed)))\n",
    "models.append(('NN', MLPClassifier(random_state=seed)))\n",
    "\n",
    "# variables to hold the results and names\n",
    "results = []\n",
    "names   = []\n",
    "\n",
    "# import the feature vector and trained labels\n",
    "h5f_data_train  = h5py.File(h5_data_train, 'r')\n",
    "h5f_label_train = h5py.File(h5_labels_train, 'r')\n",
    "\n",
    "global_features_string_train = h5f_data_train['dataset_1']\n",
    "global_labels_string_train   = h5f_label_train['dataset_1']\n",
    "\n",
    "global_features_train = np.array(global_features_string_train)\n",
    "global_labels_train   = np.array(global_labels_string_train)\n",
    "\n",
    "h5f_data_train.close()\n",
    "h5f_label_train.close()\n",
    "\n",
    "# import the feature vector and trained labels\n",
    "h5f_data_test  = h5py.File(h5_data_test, 'r')\n",
    "h5f_label_test = h5py.File(h5_labels_test, 'r')\n",
    "\n",
    "global_features_string_test = h5f_data_test['dataset_1']\n",
    "global_labels_string_test   = h5f_label_test['dataset_1']\n",
    "\n",
    "global_features_test = np.array(global_features_string_test)\n",
    "global_labels_test   = np.array(global_labels_string_test)\n",
    "\n",
    "h5f_data_test.close()\n",
    "h5f_label_test.close()\n",
    "\n",
    "\n",
    "# verify the shape of the feature vector and labels\n",
    "print(\"[STATUS] train features shape: {}\".format(global_features_train.shape))\n",
    "print(\"[STATUS] train labels shape: {}\".format(global_labels_train.shape))\n",
    "print(\"[STATUS] test features shape: {}\".format(global_features_test.shape))\n",
    "print(\"[STATUS] test labels shape: {}\".format(global_labels_test.shape))\n",
    "\n",
    "print(\"[STATUS] training started...\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[STATUS] train features shape: (3417, 154587)\n",
      "[STATUS] train labels shape: (3417,)\n",
      "[STATUS] test features shape: (825, 154587)\n",
      "[STATUS] test labels shape: (825,)\n",
      "[STATUS] training started...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# split the training and testing data\n",
    "# (trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal) = train_test_split(np.array(global_features),\n",
    "#                                                                                           np.array(global_labels),\n",
    "#                                                                                           test_size=test_size,\n",
    "#                                                                                           random_state=seed)\n",
    "\n",
    "trainDataGlobal = np.array(global_features_train)\n",
    "testDataGlobal = np.array(global_features_train)\n",
    "trainLabelsGlobal = np.array(global_labels_train)\n",
    "testLabelsGlobal = np.array(global_labels_test)\n",
    "\n",
    "print(\"[STATUS] splitted train and test data...\")\n",
    "print(\"Train data  : {}\".format(trainDataGlobal.shape))\n",
    "print(\"Test data   : {}\".format(testDataGlobal.shape))\n",
    "print(\"Train labels: {}\".format(trainLabelsGlobal.shape))\n",
    "print(\"Test labels : {}\".format(testLabelsGlobal.shape))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[STATUS] splitted train and test data...\n",
      "Train data  : (3417, 154587)\n",
      "Test data   : (3417, 154587)\n",
      "Train labels: (3417,)\n",
      "Test labels : (825,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import time \n",
    "\n",
    "# 10-fold cross validation\n",
    "for name, model in models:\n",
    "    start = time.time()\n",
    "    kfold = KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, trainDataGlobal, trainLabelsGlobal, cv=kfold, scoring=scoring)\n",
    "    end = time.time()\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    print(f\"Time to Train {end-start}\")\n",
    "\n",
    "# boxplot algorithm comparison\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Machine Learning algorithm comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LR: 0.206330 (0.019121)\n",
      "Time to Train 909.9360132217407\n",
      "LDA: 0.169147 (0.025773)\n",
      "Time to Train 1707.2374799251556\n",
      "KNN: 0.171787 (0.017938)\n",
      "Time to Train 44.09794211387634\n",
      "CART: 0.126708 (0.017718)\n",
      "Time to Train 5074.112898111343\n",
      "RF: 0.265735 (0.023702)\n",
      "Time to Train 849.8707809448242\n",
      "NB: 0.228553 (0.022012)\n",
      "Time to Train 139.10767817497253\n",
      "SVM: 0.296168 (0.026767)\n",
      "Time to Train 11293.600455999374\n",
      "NN: 0.051797 (0.011322)\n",
      "Time to Train 3758.7922868728638\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN Base Raw Model (Default Parameters)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "X_train = x_train_1d_top20\n",
    "y_train = y_train_top20 \n",
    "X_test = x_test_1d_top20\n",
    "y_test = y_test_top20\n",
    "\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "start = time.time()\n",
    "neigh = KNeighborsClassifier().fit(X_train,y_train)\n",
    "ypred_knn_base = neigh.predict(X_test)\n",
    "end = time.time()\n",
    "duration_knn_base = end - start\n",
    "\n",
    "accuracy_knn_base = metrics.accuracy_score(y_test, ypred_knn_base)\n",
    "\n",
    "print(f\"Accuracy of base KNN model is {accuracy_knn_base}\")\n",
    "print(f\"Time to tune default KNN is {duration_knn_base}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of base KNN model is 0.19757575757575757\n",
      "Time to tune default KNN is 7.2132861614227295\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN Raw Model Cross Validation (Run on Server Crashes Laptop)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "\n",
    "n_splits = 3\n",
    "n_repeats = 3\n",
    "random_state = 123\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "# define models and parameters\n",
    "model = KNeighborsClassifier()\n",
    "n_neighbors = range(1, 20, 1)\n",
    "weights = ['uniform', 'distance']\n",
    "metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "# define grid search\n",
    "grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
    "cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train,y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "end = time.time()\n",
    "duration_knn_cv = end - start  \n",
    "print(f\"Time to Cross Validate KNN is {duration_knn_cv}\")  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/teresa.dong/opt/anaconda3/envs/isye6740/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b7366dec4314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/isye6740/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/isye6740/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/isye6740/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/isye6740/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/isye6740/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/isye6740/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/isye6740/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/isye6740/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/isye6740/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Actually it appears that cross validation crashes the computer, let's not cross validate for now"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM Base Model (Default Parameters)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from sklearn.svm import SVC\n",
    "start = time.time()\n",
    "model_svm = SVC()\n",
    "model_svm.fit(X_train,y_train)\n",
    "yhat_svm = model_svm.predict(X_test)\n",
    "end = time.time()\n",
    "duration_svm_base = end - start\n",
    "print(\"Accuracy of default SVM is\",metrics.accuracy_score(y_test, yhat_svm))\n",
    "print(f\"Time to tune default SVM is {duration_svm_base}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of default SVM is 0.32484848484848483\n",
      "Time to tune default SVM is 1471.6981060504913\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM Base Model (Cross Validation)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# define model and parameters\n",
    "start = time.time()\n",
    "model = SVC()\n",
    "kernel = ['poly', 'rbf', 'sigmoid','linear']\n",
    "C = [50, 10, 1.0, 0.1, 0.01]\n",
    "gamma = [1, 0.1, 0.01, 0.001, 0.0001,'scale']\n",
    "# define grid search\n",
    "grid = dict(kernel=kernel,C=C,gamma=gamma)\n",
    "cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "end = time.time()\n",
    "duration_svm_cv = end - start  \n",
    "\n",
    "print(f\"Time to Cross Validate SVM is {duration_svm_cv}\")  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "start = time.time()\n",
    "model_log = LogisticRegression(multi_class='multinomial', solver='lbfgs',max_iter=1000)\n",
    "model_log.fit(X_train,y_train)\n",
    "yhat_log = model_log.predict(X_test)\n",
    "print(\"Accuracy of default Multinomial Logistic model is\",metrics.accuracy_score(y_test, yhat_log))\n",
    "end = time.time()\n",
    "duration_log_base = end - start  \n",
    "print(\"Accuracy of default LogReg is\",metrics.accuracy_score(y_test, yhat_log))\n",
    "print(f\"Time to tune default LogReg is {duration_log_base}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/teresa.dong/opt/anaconda3/envs/isye6740/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of default Multinomial Logistic model is 0.23515151515151514\n",
      "Accuracy of default LogReg is 0.23515151515151514\n",
      "Time to tune default LogReg is 886.0278468132019\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# define models and parameters\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "penalty = ['l1', 'l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "solvers = ['newton-cg','lbfgs']\n",
    "mcs = ['multinomial']\n",
    "\n",
    "# define grid search\n",
    "grid = dict(penalty=penalty,C=c_values,solver=solvers,multi_class=mcs)\n",
    "cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0,verbose=True)\n",
    "grid_result = grid_search.fit(X_train,y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']  \n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Networks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "start = time.time()\n",
    "model_nn = MLPClassifier()\n",
    "model_nn.fit(X_train,y_train)\n",
    "yhat_nn = model_nn.predict(X_test)\n",
    "print(\"Accuracy of default Neural Network is\",metrics.accuracy_score(y_test, yhat_nn))\n",
    "end = time.time()\n",
    "duration_nn_base = end - start  \n",
    "print(\"Accuracy of default Neural Network is\",metrics.accuracy_score(y_test, yhat_nn))\n",
    "print(f\"Time to tune default Neural Network is {duration_nn_base}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of default Neural Network is 0.052121212121212124\n",
      "Accuracy of default Neural Network is 0.052121212121212124\n",
      "Time to tune default Neural Network is 459.49992418289185\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "start = time.time()\n",
    "model_nn = MLPClassifier(hidden_layer_sizes=(10, 10, 10))\n",
    "model_nn.fit(X_train,y_train)\n",
    "yhat_nn = model_nn.predict(X_test)\n",
    "print(\"Accuracy of default Neural Network is\",metrics.accuracy_score(y_test, yhat_nn))\n",
    "end = time.time()\n",
    "duration_nn_base = end - start  \n",
    "print(\"Accuracy of default Neural Network is\",metrics.accuracy_score(y_test, yhat_nn))\n",
    "print(f\"Time to tune default Neural Network is {duration_nn_base}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of default Neural Network is 0.06666666666666667\n",
      "Accuracy of default Neural Network is 0.06666666666666667\n",
      "Time to tune default Neural Network is 154.24200105667114\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# define model and parameters\n",
    "model = MLPClassifier()\n",
    "activation = ['tanh','relu','lbfgs']\n",
    "solver = ['sgd','adam']\n",
    "alpha=[0.0001,0.05]\n",
    "learning_rate=['constant']\n",
    "max_iter=[1000]\n",
    "\n",
    "\n",
    "# define grid search\n",
    "grid = dict(activation=activation, solver=solver, hidden_layer_sizes=hidden_layer_sizes, alpha=alpha,\n",
    "            learning_rate=learning_rate, max_iter=max_iter)\n",
    "cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0,verbose=True)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('isye6740': conda)"
  },
  "interpreter": {
   "hash": "0e47db13a965e1c59211aa111ffedf6a36e5ee965871d986be01032a7155d667"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}